{
  "metadata": {
    "name": "Searchlight on fMRI data"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Searchlight on fMRI data"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The original idea of a spatial searchlight algorithm stems from a paper by\n", 
            "*Kriegeskorte et al. (2006)*, and has subsequently been used in a\nnumber of studies. The most common use for a searchlight is to compute a full\ncross-validation analysis in each spherical region of interest (ROI) in the\nbrain. This analysis yields a map of (typically) classification accuracies that\nare often interpreted or post-processed similar to a GLM statistics output map\n(e.g. subsequent analysis with inferential statistics). In this example we look\nat how this type of analysis can be conducted in PyMVPA.\n\n", 
            "As always, we first have to import PyMVPA."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from mvpa2.suite import *"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "As searchlight analyses are usually quite expensive in terms of computational\nresources, we are going to enable some progress output to entertain us while\nwe are waiting."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# enable debug output for searchlight call\nif __debug__:\n    debug.active += [\"SLC\"]"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The next few calls load an fMRI dataset, while assigning associated class\ntargets and chunks (experiment runs) to each volume in the 4D timeseries.  One\naspect is worth mentioning. When loading the fMRI data with\n", 
            "[fmri_dataset()](http://pymvpa.org/generated/mvpa2.datasets.mri.fmri_dataset.html#mvpa2-datasets-mri-fmri-dataset) additional feature attributes can be\nadded, by providing a dictionary with names and source pairs to the ", 
            "`add_fa`\narguments. In this case we are loading a thresholded zstat-map of a category\nselectivity contrast for voxels ventral temporal cortex."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# data path\ndatapath = os.path.join(mvpa2.cfg.get('location', 'tutorial data'), 'haxby2001')\ndataset = load_tutorial_data(\n        roi='brain',\n        add_fa={'vt_thr_glm': os.path.join(datapath, 'sub001', 'masks',\n                                                     'orig', 'vt.nii.gz')})"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The dataset is now loaded and contains all brain voxels as features, and all\nvolumes as samples. To precondition this data for the intended analysis we have\nto perform a few preprocessing steps (please note that the data was already\nmotion-corrected). The first step is a chunk-wise (run-wise) removal of linear\ntrends, typically caused by the acquisition equipment."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "poly_detrend(dataset, polyord=1, chunks_attr='chunks')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Now that the detrending is done, we can remove parts of the timeseries we\nare not interested in. For this example we are only considering volumes acquired\nduring a stimulation block with images of houses and scrambled pictures, as well\nas rest periods (for now). It is important to perform the detrending before\nthis selection, as otherwise the equal spacing of fMRI volumes is no longer\nguaranteed."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "dataset = dataset[np.array([l in ['rest', 'house', 'scrambledpix']\n                           for l in dataset.targets], dtype='bool')]"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The final preprocessing step is data-normalization. This is a required step\nfor many classification algorithms. It scales all features (voxels)\ninto approximately the same range and removes the mean. In this example, we\nperform a chunk-wise normalization and compute standard deviation and mean for\nz-scoring based on the volumes corresponding to rest periods in the experiment.\nThe resulting features could be interpreted as being voxel salience relative\nto 'rest'."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "zscore(dataset, chunks_attr='chunks', param_est=('targets', ['rest']), dtype='float32')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "After normalization is completed, we no longer need the 'rest'-samples and\nremove them."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "dataset = dataset[dataset.sa.targets != 'rest']"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "But now for the interesting part: Next we define the measure that shall be\ncomputed for each sphere. Theoretically, this can be anything, but here we\nchoose to compute a full leave-one-out cross-validation using a linear Nu-SVM\nclassifier."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# choose classifier\nclf = LinearNuSVMC()\n\n# setup measure to be computed by Searchlight\n# cross-validated mean transfer using an N-fold dataset splitter\ncv = CrossValidation(clf, NFoldPartitioner())"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "In this example, we do not want to compute full-brain accuracy maps, but\ninstead limit ourselves to a specific subset of voxels. We'll select all voxel\nthat have a non-zero z-stats value in the localizer mask we loaded above, as\ncenter coordinates for a searchlight sphere. These spheres will still include\nvoxels that did not pass the threshold. the localizer merely define the\nlocation of all to be processed spheres."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# get ids of features that have a nonzero value\ncenter_ids = dataset.fa.vt_thr_glm.nonzero()[0]"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Finally, we can run the searchlight. We'll perform the analysis for three\ndifferent radii, each time computing an error for each sphere. To achieve this,\nwe simply use the ", 
            "[sphere_searchlight()](http://pymvpa.org/generated/mvpa2.measures.searchlight.sphere_searchlight.html#mvpa2-measures-searchlight-sphere-searchlight) class,\nwhich takes any ", 
            "[processing object](http://pymvpa.org/glossary.html#term-processing-object) and a radius as arguments. The\n", 
            "[processing object](http://pymvpa.org/glossary.html#term-processing-object) has to compute the intended measure, when called with\na dataset. The ", 
            "[sphere_searchlight()](http://pymvpa.org/generated/mvpa2.measures.searchlight.sphere_searchlight.html#mvpa2-measures-searchlight-sphere-searchlight) object\nwill do nothing more than generate small datasets for each sphere, feeding them\nto the processing object, and storing the result."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# setup plotting parameters (not essential for the analysis itself)\nplot_args = {\n    'background' : os.path.join(datapath, 'sub001', 'anatomy', 'highres001.nii.gz'),\n    'background_mask' : os.path.join(datapath, 'sub001', 'masks', 'orig', 'brain.nii.gz'),\n    'overlay_mask' : os.path.join(datapath, 'sub001', 'masks', 'orig', 'vt.nii.gz'),\n    'do_stretch_colors' : False,\n    'cmap_bg' : 'gray',\n    'cmap_overlay' : 'autumn', # YlOrRd_r # pl.cm.autumn\n    'interactive' : cfg.getboolean('examples', 'interactive', True),\n    }\n\nfor radius in [0, 1, 3]:\n    # tell which one we are doing\n    print \"Running searchlight with radius: %i ...\" % (radius)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Here we actually setup the spherical searchlight by configuring the\nradius, and our selection of sphere center coordinates. Moreover, via the\n", 
            "`space` argument we can instruct the searchlight which feature attribute\nshall be used to determine the voxel neighborhood. By default,\n", 
            "[fmri_dataset()](http://pymvpa.org/generated/mvpa2.datasets.mri.fmri_dataset.html#mvpa2-datasets-mri-fmri-dataset) creates a corresponding attribute\ncalled ", 
            "`voxel_indices`.  Using the ", 
            "`mapper` argument it is possible to\npost-process the results computed for each sphere. Cross-validation will\ncompute an error value per each fold, but here we are only interested in\nthe mean error across all folds. Finally, on multi-core machines ", 
            "`nproc`\ncan be used to enabled parallelization by setting it to the number of\nprocesses utilized by the searchlight (default value of ", 
            "`nproc`=`None` utilizes\nall available local cores)."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    sl = sphere_searchlight(cv, radius=radius, space='voxel_indices',\n                             center_ids=center_ids,\n                             postproc=mean_sample())"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Since we care about efficiency, we are stripping all attributes from the\ndataset that are not required for the searchlight analysis. This will offers\nsome speedup, since it reduces the time that is spent on dataset slicing."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    ds = dataset.copy(deep=False,\n                       sa=['targets', 'chunks'],\n                       fa=['voxel_indices'],\n                       a=['mapper'])"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Finally, we actually run the analysis. The result is returned as a\ndataset. For the upcoming plots, we are transforming the returned error\nmaps into accuracies."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    sl_map = sl(ds)\n     sl_map.samples *= -1\n     sl_map.samples += 1"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The result dataset is fully aware of the original dataspace. Using this\ninformation we can map the 1D accuracy maps back into \"brain-space\" (using\nNIfTI image header information from the original input timeseries."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    niftiresults = map2nifti(sl_map, imghdr=dataset.a.imghdr)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "PyMVPA comes with a convenient plotting function to visualize the\nsearchlight maps. We are only looking at fMRI slices that are covered\nby the mask of ventral temproal cortex."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    fig = pl.figure(figsize=(12, 4), facecolor='white')\n     subfig = plot_lightbox(overlay=niftiresults,\n                            vlim=(0.5, None), slices=range(23,31),\n                            fig=fig, **plot_args)\n     pl.title('Accuracy distribution for radius %i' % radius)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The following figures show the resulting accuracy maps for the slices\ncovered by the ventral temporal cortex mask. Note that each voxel value\nrepresents the accuracy of a sphere centered around this voxel.\n\n\\[Visit [http://pymvpa.org/examples/searchlight.html](http://pymvpa.org/examples/searchlight.html) to view this figure\\]\n\n\\[Visit [http://pymvpa.org/examples/searchlight.html](http://pymvpa.org/examples/searchlight.html) to view this figure\\]\n\n\\[Visit [http://pymvpa.org/examples/searchlight.html](http://pymvpa.org/examples/searchlight.html) to view this figure\\]\n\n", 
            "With radius 0 (only the center voxel is part of the part the sphere) there is a\nclear distinction between two distributions. The ", 
            "*chance distribution*,\nrelatively symetric and centered around the expected chance-performance at 50%.\nThe second distribution, presumambly of voxels with univariate signal, is nicely\nsegregated from that. Increasing the searchlight size significantly blurrs the\naccuracy map, but also lead to an increase in classification accuracy."
          ]
        }
      ], 
      "metadata": {}
    }
  ]
}