{
  "metadata": {
    "name": "Efficient cross-validation using a cached kernel"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Efficient cross-validation using a cached kernel"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "This is a simple example showing how to use cached kernel with a SVM\nclassifier from the Shogun library.  Pre-caching of the kernel for all\nsamples in dataset eliminates necessity of possibly lengthy\nrecomputation of the same kernel values on different splits of the\ndata.  Depending on the data it might provide considerable speed-ups."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from mvpa2.suite import *\nfrom time import time"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The next few calls load an fMRI dataset and do basic preprocessing."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# load PyMVPA example dataset\nattr = SampleAttributes(os.path.join(pymvpa_dataroot,\n                        'attributes_literal.txt'))\ndataset = fmri_dataset(samples=os.path.join(pymvpa_dataroot, 'bold.nii.gz'),\n                       targets=attr.targets, chunks=attr.chunks,\n                       mask=os.path.join(pymvpa_dataroot, 'mask.nii.gz'))\n\n# do chunkswise linear detrending on dataset\npoly_detrend(dataset, polyord=1, chunks_attr='chunks')\n\n# zscore dataset relative to baseline ('rest') mean\nzscore(dataset, chunks_attr='chunks', param_est=('targets', ['rest']))"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Cached kernel is just a proxy around an existing kernel."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# setup a cached kernel\nkernel_plain = LinearSGKernel(normalizer_cls=False)\nkernel = CachedKernel(kernel_plain)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Lets setup two cross-validation, where first would use cached\nkernel, whenever the later one plain kernel to demonstrate the\nspeed-up and achievement of exactly the same results"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# setup a classifier and cross-validation procedure\nclf = sg.SVM(svm_impl='libsvm', C=-1.0, kernel=kernel)\ncv = CrossValidation(clf, NFoldPartitioner())\n\n# setup exactly the same using a plain kernel for demonstration of\n# speedup and equivalence of the results\nclf_plain = sg.SVM(svm_impl='libsvm', C=-1.0, kernel=kernel_plain)\ncv_plain = CrossValidation(clf_plain, NFoldPartitioner())"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Although it would be done internally by cached kernel during\ninitial computation, it is advisable to make initialization of origids\nfor samples explicit. It would prepare dataset by cleaning up\nattributes used by cached kernel possibly on another version of the\nsame dataset prior to this analysis in real use cases."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "dataset.init_origids(which='samples')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Cached kernel needs to be computed given the full dataset which\nwould later on be used during cross-validation."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# compute kernel for the dataset\nt0 = time()\nkernel.compute(dataset)\nt_caching = time() - t0"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Lets run both cross-validation procedures using plain and cached\nkernels and report the results."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# run cached cross-validation\nt0 = time()\nerror = np.mean(cv(dataset))\nt_cached = time() - t0\n\n# run plain SVM cross-validation for validation and benchmarking\nt0 = time()\nerror_plain = np.mean(cv_plain(dataset))\nt_plain = time() - t0\n\n# UC: unique chunks, UT: unique targets\nprint \"Results for %i-fold cross-validation on %i-class problem:\" \\\n      % (len(dataset.UC), len(dataset.UT))\nprint \" plain kernel:  error=%.3f computed in %.2f sec\" \\\n      % (error_plain, t_plain)\nprint \" cached kernel: error=%.3f computed in %.2f sec (cached in %.2f sec)\" \\\n      % (error, t_cached, t_caching)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The following is output from running this example:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "Results for 12-fold cross-validation on 9-class problem:\n plain kernel:  error=0.273 computed in 35.82 sec\n cached kernel: error=0.273 computed in 6.50 sec (cached in 3.68 sec)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }
      ], 
      "metadata": {}
    }
  ]
}