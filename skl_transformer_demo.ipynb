{
  "metadata": {
    "name": "Using scikit-learn transformers with PyMVPA"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Using scikit-learn transformers with PyMVPA"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Scikit-learn is a rich library of algorithms, many of them implementing the\n", 
            "[transformer API](http://scikit-learn.org/stable/developers/#apis-of-scikit-learn-objects). PyMVPA provides a wrapper class,\n", 
            "[SKLTransformer](http://pymvpa.org/generated/mvpa2.mappers.skl_adaptor.SKLTransformer.html#mvpa2-mappers-skl-adaptor-skltransformer) that enables the use\nof all of these algorithms within the PyMVPA framework. With this adaptor\nthe transformer API is presented as a PyMVPA mapper interface that is fully\ncompatible with all other building blocks of PyMVPA.\n\n", 
            "In this example we demonstrate this interface by mimicking the \"", 
            "[Comparison of Manifold Learning methods](http://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html)\" example from the scikit-learn documentation --\napplying the minimal modifications necessary to run a variety of scikit-learn\nalgorithm implementation on PyMVPA datasets.\n\n", 
            "This script also prints the same timing information as the original."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print(__doc__)\n\nfrom time import time\n\nimport pylab as pl\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.ticker import NullFormatter\n\nfrom sklearn import manifold\n# Next line to silence pyflakes. This import is needed.\nAxes3D\n\nn_points = 1000\nn_neighbors = 10\nn_components = 2"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "So far the code has been identical. The first difference is the import of the\nadaptor class. We also load the scikit-learn demo dataset, but also with the\nhelp of a wrapper function that yields a PyMVPA dataset."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# this first import is only required to run the example a part of the test suite\nfrom mvpa2 import cfg\nfrom mvpa2.mappers.skl_adaptor import SKLTransformer\n\n# load the S-curve dataset\nfrom mvpa2.datasets.sources.skl_data import skl_s_curve\nds = skl_s_curve(n_points)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "And we continue with practically identical code."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "fig = pl.figure(figsize=(15, 8))\npl.suptitle(\"Manifold Learning with %i points, %i neighbors\"\n            % (1000, n_neighbors), fontsize=14)\n\ntry:\n    # compatibility matplotlib < 1.0\n    X = ds.samples\n    ax = fig.add_subplot(241, projection='3d')\n    ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=ds.targets, cmap=pl.cm.Spectral)\n    ax.view_init(4, -72)\nexcept:\n    X = ds.samples\n    ax = fig.add_subplot(241, projection='3d')\n    pl.scatter(X[:, 0], X[:, 2], c=ds.targets, cmap=pl.cm.Spectral)\n\nmethods = ['standard', 'ltsa', 'hessian', 'modified']\nlabels = ['LLE', 'LTSA', 'Hessian LLE', 'Modified LLE']\n\nfor i, method in enumerate(methods):\n    t0 = time()\n    # create an instance of the algorithm from scikit-learn\n    # and wrap it by SKLTransformer"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The following lines are an example of the only significant modification\nwith respect to a pure scikit-learn implementation: the transformer is\nwrapped into the adaptor.  The result is a mapper, hence can be called\nwith a dataset that contains both samples and targets -- without explcitly\ncalling `fit()` and `transform()`."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    lle = SKLTransformer(manifold.LocallyLinearEmbedding(n_neighbors,\n                                                          n_components,\n                                                          eigen_solver='auto',\n                                                          method=method))\n     # call the SKLTransformer instance on the input dataset\n     Y = lle(ds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The rest of the example is unmodified except for the wrapping of the\nrespective transformer into the Mapper adaptor."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    t1 = time()\n     print(\"%s: %.2g sec\" % (methods[i], t1 - t0))\n\n     ax = fig.add_subplot(242 + i)\n     pl.scatter(Y[:, 0], Y[:, 1], c=ds.targets, cmap=pl.cm.Spectral)\n     pl.title(\"%s (%.2g sec)\" % (labels[i], t1 - t0))\n     ax.xaxis.set_major_formatter(NullFormatter())\n     ax.yaxis.set_major_formatter(NullFormatter())\n     pl.axis('tight')\n\n t0 = time()\n # create an instance of the algorithm from scikit-learn\n # and wrap it by SKLTransformer\n iso = SKLTransformer(manifold.Isomap(n_neighbors=10, n_components=2))\n # call the SKLTransformer instance on the input dataset\n Y = iso(ds)\n t1 = time()\n print(\"Isomap: %.2g sec\" % (t1 - t0))\n ax = fig.add_subplot(246)\n pl.scatter(Y[:, 0], Y[:, 1], c=ds.targets, cmap=pl.cm.Spectral)\n pl.title(\"Isomap (%.2g sec)\" % (t1 - t0))\n ax.xaxis.set_major_formatter(NullFormatter())\n ax.yaxis.set_major_formatter(NullFormatter())\n pl.axis('tight')\n\n\n t0 = time()\n # create an instance of the algorithm from scikit-learn\n # and wrap it by SKLTransformer\n mds = SKLTransformer(manifold.MDS(n_components=2, max_iter=100,\n                                   n_init=1, dissimilarity='euclidean'))\n # call the SKLTransformer instance on the input dataset\n Y = mds(ds)\n t1 = time()\n print(\"MDS: %.2g sec\" % (t1 - t0))\n ax = fig.add_subplot(247)\n pl.scatter(Y[:, 0], Y[:, 1], c=ds.targets, cmap=pl.cm.Spectral)\n pl.title(\"MDS (%.2g sec)\" % (t1 - t0))\n ax.xaxis.set_major_formatter(NullFormatter())\n ax.yaxis.set_major_formatter(NullFormatter())\n pl.axis('tight')\n\n\n t0 = time()\n # create an instance of the algorithm from scikit-learn\n # and wrap it by SKLTransformer\n se = SKLTransformer(manifold.SpectralEmbedding(n_components=n_components,\n                                                n_neighbors=n_neighbors))\n # call the SKLTransformer instance on the input dataset\n Y = se(ds)\n t1 = time()\n print(\"SpectralEmbedding: %.2g sec\" % (t1 - t0))\n ax = fig.add_subplot(248)\n pl.scatter(Y[:, 0], Y[:, 1], c=ds.targets, cmap=pl.cm.Spectral)\n pl.title(\"SpectralEmbedding (%.2g sec)\" % (t1 - t0))\n ax.xaxis.set_major_formatter(NullFormatter())\n ax.yaxis.set_major_formatter(NullFormatter())\n pl.axis('tight')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }
      ], 
      "metadata": {}
    }
  ]
}