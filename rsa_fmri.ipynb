{
  "metadata": {
    "name": "Representational similarity analysis (RSA) on fMRI data"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Representational similarity analysis (RSA) on fMRI data"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "In this example we are going to take a look at representational similarity\nanalysis (RSA). This term was coined by ", 
            "*Kriegeskorte et al. (2008)* and refers to a technique were data samples are converted into a\nself-referential distance space, in order to aid comparsion across domains. The\npremise is that whenever no appropriate transformation is known to directly\ncompare two types of data directly (1st-level), it is still useful to compare\nsimilarities computed in individual domains (2nd-level). For example, this\nanalysis technique has been used to identify inter-species commonalities in\nbrain response pattern variations during stimulation with visual objects\n(single-cell recordings in monkeys compared to human fMRI, Krigeskorte et al.,\n2008), and to relate brain response pattern similarities to predictions of\ncomputational models of perception (Connolly et al., 2012)."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "import numpy as np\nimport pylab as pl\nfrom os.path import join as pjoin\nfrom mvpa2 import cfg"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "In this example we use a dataset from ", 
            "*Haxby et al. (2001)* were\nparticipants watched pictures of eight different visual objects, while fMRI was\nrecorded. The following snippet load a portion of this dataset (single subject)\nfrom regions on the ventral and occipital surface of the brain."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# load dataset -- ventral and occipital ROIs\nfrom mvpa2.datasets.sources.native import load_tutorial_data\ndatapath = pjoin(cfg.get('location', 'tutorial data'), 'haxby2001')\nds = load_tutorial_data(roi=(15, 16, 23, 24, 36, 38, 39, 40, 48))"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "We only do minimal pre-processing: linear trend removal and Z-scoring all voxel\ntime-series with respect to the mean and standard deviation of the \"rest\"\ncondition."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# only minial detrending\nfrom mvpa2.mappers.detrend import poly_detrend\npoly_detrend(ds, polyord=1, chunks_attr='chunks')\n# z-scoring with respect to the 'rest' condition\nfrom mvpa2.mappers.zscore import zscore\nzscore(ds, chunks_attr='chunks', param_est=('targets', 'rest'))\n# now remove 'rest' samples\nds = ds[ds.sa.targets != 'rest']"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "RSA is all about so-called dissimilarity matrices: square, symetric matrices\nwith a zero diagonal that encode the (dis)similarity between all pairs of\ndata samples or conditions in a dataset. We compose a little helper function\nto plot such matrices, including a color-scale and proper labeling of matrix\nrows and columns."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# little helper function to plot dissimilarity matrices\ndef plot_mtx(mtx, labels, title):\n    pl.figure()\n    pl.imshow(mtx, interpolation='nearest')\n    pl.xticks(range(len(mtx)), labels, rotation=-45)\n    pl.yticks(range(len(mtx)), labels)\n    pl.title(title)\n    pl.clim((0,1))\n    pl.colorbar()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "As a start, we want to inspect the dissimilarity structure of the stimulation\nconditions in the entire ROI. For this purpose, we average all samples of\neach conditions into a single examplar, using an FxMapper() instance."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# compute a dataset with the mean samples for all conditions\nfrom mvpa2.mappers.fx import mean_group_sample\nmtgs = mean_group_sample(['targets'])\nmtds = mtgs(ds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "After these preparations we can use the PDist() measure to compute the desired\ndistance matrix -- by default using correlation distance as a metric. The\n`square` argument will cause a ful square matrix to be\nproduced, instead of a leaner upper-triangular matrix in vector form."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# basic ROI RSA -- dissimilarity matrix for the entire ROI\nfrom mvpa2.measures import rsa\ndsm = rsa.PDist(square=True)\nres = dsm(mtds)\nplot_mtx(res, mtds.sa.targets, 'ROI pattern correlation distances')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Inspecting the figure we can see that there is not much structure in the matrix,\nexcept for the face and the house condition being slightly more dissimilar than\nothers.\n\n", 
            "Now, let's take a look at the variation of similarity structure through the\nbrain. We can plug the PDist() measure into a searchlight to quickly scan the\nbrain and harvest this information."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# same as above, but done in a searchlight fashion\nfrom mvpa2.measures.searchlight import sphere_searchlight\ndsm = rsa.PDist(square=False)\nsl = sphere_searchlight(dsm, 2)\nslres = sl(mtds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The result is a compact distance matrix in vector form for each searchlight\nlocation. We can now try to score each matrix. Let's find the distance matrix\nwith the largest overall distances across all stimulation conditions, i.e.\nthe location in the brain where brain response patterns are most dissimilar."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# score each searchlight sphere result wrt global pattern dissimilarity\ndistinctiveness = np.sum(np.abs(slres), axis=0)\nprint 'Most dissimilar patterns around', \\\n        mtds.fa.voxel_indices[distinctiveness.argmax()]\n# take a look at the this dissimilarity structure\nfrom scipy.spatial.distance import squareform\nplot_mtx(squareform(slres.samples[:, distinctiveness.argmax()]),\n         mtds.sa.targets,\n         'Maximum distinctive searchlight pattern correlation distances')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "That looks confusing. But how do we know that this is not just noise (it\nprobably is)? One way would be to look at how stable a distance matrix is,\nwhen computed for different portions of a dataset.\n\n", 
            "To perform this analysis, we use another FxMapper() instance that averages\nall data into a single sample per stimulation conditions, per `chunk`. A\nchunk in this context indicates a complete fMRI recording run."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# more interesting: let's look at the stability of similarity sturctures\n# across experiment runs\n# mean condition samples, as before, but now individually for each run\nmtcgs = mean_group_sample(['targets', 'chunks'])\nmtcds = mtcgs(ds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "With this dataset we can use PDistConsistency() to compute the similarity\nof dissimilarity matrices computes from different chunks. And, of course,\nit can be done in a searchlight."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# searchlight consistency measure -- how correlated are the structures\n# across runs\ndscm = rsa.PDistConsistency()\nsl_cons = sphere_searchlight(dscm, 2)\nslres_cons = sl_cons(mtcds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Now we can determine the most brain location with the most stable\ndissimilarity matrix."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# mean correlation\nmean_consistency = np.mean(slres_cons, axis=0)\nprint 'Most stable dissimilarity patterns around', \\\n        mtds.fa.voxel_indices[mean_consistency.argmax()]\n# Look at this pattern\nplot_mtx(squareform(slres.samples[:, mean_consistency.argmax()]),\n         mtds.sa.targets,\n         'Most consistent searchlight pattern correlation distances')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "It is all in the face!\n\n", 
            "It would be interesting to know where in the brain dissimilarity structures\ncan be found that are similar to this one. PDistTargetSimilarity() can\nbe used to discover this kind of information with any kind of target\ndissimilarity structure. We need to transpose the result for aggregation\ninto a searchlight map, as PDistTargetSimilarity can return more features\nthan just the correlation coefficient."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# let's see where in the brain we find dissimilarity structures that are\n# similar to our most stable one\ntdsm = rsa.PDistTargetSimilarity(\n            slres.samples[:, mean_consistency.argmax()])\n# using a searchlight\nfrom mvpa2.base.learner import ChainLearner\nfrom mvpa2.mappers.shape import TransposeMapper\nsl_tdsm = sphere_searchlight(ChainLearner([tdsm, TransposeMapper()]), 2)\nslres_tdsm = sl_tdsm(mtds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Lastly, we can map this result back onto the 3D voxel grid, and overlay\nit onto the brain anatomy."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# plot the spatial distribution using NiPy\nvol = ds.a.mapper.reverse1(slres_tdsm.samples[0])\nimport nibabel as nb\nanat = nb.load(pjoin(datapath, 'sub001', 'anatomy', 'highres001.nii.gz'))\n\nfrom nipy.labs.viz_tools.activation_maps import plot_map\npl.figure(figsize=(15,4))\nsp = pl.subplot(121)\npl.title('Distribution of target similarity structure correlation')\nslices = plot_map(\n            vol,\n            ds.a.imgaffine,\n            cut_coords=np.array((12,-42,-20)),\n            threshold=.5,\n            cmap=\"bwr\",\n            vmin=0,\n            vmax=1.,\n            axes=sp,\n            anat=anat.get_data(),\n            anat_affine=anat.get_affine(),\n         )\nimg = pl.gca().get_images()[1]\ncax = pl.axes([.05, .05, .05, .9])\npl.colorbar(img, cax=cax)\n\nsp = pl.subplot(122)\npl.hist(slres_tdsm.samples[0],\n        #range=(0,410),\n        normed=False,\n        bins=30,\n        color='0.6')\npl.ylabel(\"Number of voxels\")\npl.xlabel(\"Target similarity structure correlation\")"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }
      ], 
      "metadata": {}
    }
  ]
}