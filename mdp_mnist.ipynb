{
  "metadata": {
    "name": "Classifying the MNIST handwritten digits with MDP"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Classifying the MNIST handwritten digits with MDP"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "This example will demonstrate how to embed ", 
            "[MDP](http://mdp-toolkit.sourceforge.net)'s ", 
            "[flows](http://mdp-toolkit.sourceforge.net/tutorial/flows.html) into a PyMVPA-based\nanalysis. We will perform a classification of a large number of images of\nhandwritten digits from the ", 
            "*MNIST* database. To get a\nbetter sense of how MDP blends into PyMVPA, we will do the same analysis with\nMDP only first, and then redo it in PyMVPA -- only using particular bits from\nMDP.\n\n", 
            "But first we need some helper to load the MNIST data. The following function\nwill load four NumPy arrays from an HDF5 file in the PyMVPA Data DB. These\narrays are the digit images and the numerical labels for training and testing\ndataset respectively. All 28x28 pixel images are stored as flattened vectors."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "import os\nfrom mvpa2.base.hdf5 import h5load\nfrom mvpa2 import pymvpa_datadbroot\n\ndef load_data():\n    data = h5load(os.path.join(pymvpa_datadbroot, 'mnist', \"mnist.hdf5\"))\n    traindata = data['train'].samples\n    trainlabels = data['train'].sa.labels\n    testdata = data['test'].samples\n    testlabels = data['test'].sa.labels\n    return traindata, trainlabels, testdata, testlabels"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "MDP-style classification"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Here is how to get the classification of the digit images done in MDP.  The\ndata is preprocessed by whitening, followed by polynomial expansion, and a\nsubsequent projection on a nine-dimensional discriminant analysis solution.\nThere is absolutely no need to do this particular pre-processing, it is just\ndone to show off some MDP features. The actual classification is performed\nby a Gaussian classifier. The training data needs to be fed in different ways\nto the individual nodes of the flow. The whitening needs only the images,\npolynomial expansion needs no training at all, and FDA as well as the\nclassifier also need the labels. Moreover, a custom iterator is used to feed\ndata in chunks to the last two nodes of the flow."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "import numpy as np\nimport mdp\n\nclass DigitsIterator:\n    def __init__(self, digits, labels):\n        self.digits = digits\n        self.targets = labels\n    def __iter__(self):\n        frac = 10\n        ll = len(self.targets)\n        for i in xrange(frac):\n            yield self.digits[i*ll/frac:(i+1)*ll/frac], \\\n                  self.targets[i*ll/frac:(i+1)*ll/frac]\n\ntraindata, trainlabels, testdata, testlabels = load_data()\n\nfdaclf = (mdp.nodes.WhiteningNode(output_dim=10, dtype='d') +\n          mdp.nodes.PolynomialExpansionNode(2) +\n          mdp.nodes.FDANode(output_dim=9) +\n          mdp.nodes.GaussianClassifier())\n\nfdaclf.verbose = True\n\nfdaclf.train([[traindata],\n               None,\n               DigitsIterator(traindata,\n                              trainlabels),\n               DigitsIterator(traindata,\n                              trainlabels)\n               ])"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "After training, we feed the test data through the flow to obtain the\npredictions. First through the pre-processing nodes and then through\nthe classifier, extracting the predicted labels only. Finally, the\nprediction error is computed."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "feature_space = fdaclf[:-1](testdata)\nguess = fdaclf[-1].label(feature_space)\nerr = 1 - np.mean(guess == testlabels)\nprint 'Test error:', err"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Doing it the PyMVPA way"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Analog to the previous approach we load the data first. This time, however,\nwe convert it into a PyMVPA dataset. Training and testing data are initially\ncreated as two separate datasets, get tagged as 'train' and 'test' respectively,\nand are finally stacked into a single Dataset of 70000 images and their\nnumerical labels."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "import pylab as pl\nfrom mvpa2.suite import *\n\ntraindata, trainlabels, testdata, testlabels = load_data()\ntrain = dataset_wizard(\n        traindata,\n        targets=trainlabels,\n        chunks='train')\ntest = dataset_wizard(\n        testdata,\n        targets=testlabels,\n        chunks='test')\n# merge the datasets into on\nds = vstack((train, test))\nds.init_origids('samples')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "For this analysis we will use the exact same pre-processing as in the MDP\ncode above, by using the same MDP nodes, in an MDP flow that is shortened only\nby the Gaussian classifier. The glue between these MDP nodes and PyMVPA is the\n", 
            "[MDPFlowMapper](http://pymvpa.org/generated/mvpa2.mappers.mdp_adaptor.MDPFlowMapper.html#mvpa2-mappers-mdp-adaptor-mdpflowmapper). This mapper is able to supply\nnodes with optional arguments for their training. In this example a\n", 
            "[DatasetAttributeExtractor](http://pymvpa.org/generated/mvpa2.base.dataset.DatasetAttributeExtractor.html#mvpa2-base-dataset-datasetattributeextractor) is used to feed the\nlabels of the training dataset to the FDA node (in addition to the training\ndata itself)."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "fdaflow = (mdp.nodes.WhiteningNode(output_dim=10, dtype='d') +\n           mdp.nodes.PolynomialExpansionNode(2) +\n           mdp.nodes.FDANode(output_dim=9))\nfdaflow.verbose = True\n\nmapper = MDPFlowMapper(fdaflow,\n                       ([], [], [DatasetAttributeExtractor('sa', 'targets')]))"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The ", 
            "[MDPFlowMapper](http://pymvpa.org/generated/mvpa2.mappers.mdp_adaptor.MDPFlowMapper.html#mvpa2-mappers-mdp-adaptor-mdpflowmapper) can represent any MDP flow\nas a PyMVPA mapper. In this example, we attach the MDP-based pre-processing\nflow, wrapped in the mapper, to a classifier (arbitrarily chosen to be SMLR)\nvia a ", 
            "[MappedClassifier](http://pymvpa.org/generated/mvpa2.clfs.meta.MappedClassifier.html#mvpa2-clfs-meta-mappedclassifier). In doing so we achieve that\nthe training data is automatically pre-processed before it is used to train the\nclassifier, and later on the same pre-processing it applied to the testing data,\nbefore the classifier is asked to make its predictions.\n\n", 
            "At last we wrap the MappedClassifier into a\n", 
            "[TransferMeasure](http://pymvpa.org/generated/mvpa2.measures.base.TransferMeasure.html#mvpa2-measures-base-transfermeasure) that splits the dataset into a\ntraining and testing part. In this particular case this is not really\nnecessary, as we could have left training and testing data separate in the\nfirst place, and could have called the classifier's `train()` and\n`predict()` manually. However, when doing repeated train/test cycles as, for\nexample, in a cross-validation this is not very useful. In this particular case\nthe TransferMeasure computes a number of performance measures for us that we\nonly need to extract."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "tm = TransferMeasure(MappedClassifier(SMLR(), mapper),\n                     Splitter('chunks', attr_values=['train', 'test']),\n                     enable_ca=['stats', 'samples_error'])\ntm(ds)\nprint 'Test error:', 1 - tm.ca.stats.stats['ACC']"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "heading", 
          "level": 2, 
          "metadata": {}, 
          "source": [
            "Visualizing data and results"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The analyses are already done. But for the sake of completeness we take a final\nlook at both data and results. First and few examples of the training data."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "examples = [3001 + 5940 * i for i in range(10)]\n\npl.figure(figsize=(2, 5))\n\nfor i, id_ in enumerate(examples):\n    ax = pl.subplot(2, 5, i+1)\n    ax.axison = False\n    pl.imshow(traindata[id_].reshape(28, 28).T, cmap=pl.cm.gist_yarg,\n             interpolation='nearest', aspect='equal')\n\npl.subplots_adjust(left=0, right=1, bottom=0, top=1,\n                  wspace=0.05, hspace=0.05)\npl.draw()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "And finally we take a peak at the result of pre-processing for a number of\nexample images for each digit. The following plot shows the training data on\nhand-picked three-dimensional subset of the original nine FDA dimension the\ndata was projected on."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "if externals.exists('matplotlib') \\\n   and externals.versions['matplotlib'] >= '0.99':\n    from mpl_toolkits.mplot3d import Axes3D\n    pts = []\n    for i, ex in enumerate(examples):\n        pts.append(mapper.forward(ds.samples[ex:ex+200])[:, :3])\n\n    fig = pl.figure()\n\n    ax = Axes3D(fig)\n    colors = ('r','g','b','k','c','m','y','burlywood','chartreuse','gray')\n    clouds = []\n    for i, p in enumerate(pts):\n        print i\n        clouds.append(ax.plot(p[:, 0], p[:, 1], p[:, 2], 'o', c=colors[i],\n                              label=str(i), alpha=0.6))\n\n    ax.legend([str(i) for i in range(10)])\n    pl.draw()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n\\[Visit [http://pymvpa.org/examples/mdp_mnist.html](http://pymvpa.org/examples/mdp_mnist.html) to view this figure\\]\n\n", 
            "Note: The data visualization depends on the 3D matplotlib features, which are\navailable only from version 0.99."
          ]
        }
      ], 
      "metadata": {}
    }
  ]
}