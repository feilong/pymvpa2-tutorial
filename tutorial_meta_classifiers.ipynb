{
  "metadata": {
    "name": "Classifiers that do more -- Meta Classifiers"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Classifiers that do more -- Meta Classifiers"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "In ", 
            "*chap_tutorial_classifiers* we saw that it is possible to encapsulate a\nwhole cross-validation analysis into a single object that can be called with\nany dataset to produce the desired results. We also saw that despite this\nencapsulation we can still get a fair amount of information about the performed\nanalysis.  However, what happens if we want to do some further processing of\nthe data ", 
            "**within** the cross-validation analysis. That seems to be difficult,\nsince we feed a whole dataset into the analysis, and only internally does it\nget split into the respective pieces.\n\n", 
            "Of course there is a solution to this problem -- a ", 
            "[meta-classifier](http://pymvpa.org/glossary.html#term-meta-classifier).\nThis is a classifier that doesn't implement a classification algorithm on\nits own, but uses another classifier to do the actual work. In addition,\nthe meta-classifier adds another processing step that is performed before\nthe actual ", 
            "[base-classifier](http://pymvpa.org/glossary.html#term-base-classifier) sees the data.\n\n", 
            "An example of such a meta-classifier is ", 
            "[MappedClassifier](http://pymvpa.org/generated/mvpa2.clfs.meta.MappedClassifier.html#mvpa2-clfs-meta-mappedclassifier).\nIts purpose is simple: Apply a mapper to both training and testing data\nbefore it is passed on to the internal base-classifier. With this technique\nit is possible to implement arbitrary pre-processing within a\ncross-validation analysis.\n\n", 
            "Before we get into that, let's reproduce the dataset from\n", 
            "*chap_tutorial_classifiers*:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from mvpa2.tutorial_suite import *\n", 
            "datapath = os.path.join(tutorial_data_path, 'data')\n", 
            "ds = load_tutorial_data(roi='vt')\n", 
            "poly_detrend(ds, polyord=1, chunks_attr='chunks')\n", 
            "zscore(ds, param_est=('targets', ['rest']))\n", 
            "ds = ds[ds.sa.targets != 'rest']\n", 
            "run_averager = mean_group_sample(['targets', 'chunks'])\n", 
            "ds = ds.get_mapped(run_averager)\n", 
            "ds.shape"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Now, suppose we want to perform the classification not on voxel intensities\nthemselves, but on the same samples in the space spanned by the singular\nvectors of the training data, it would look like this:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "baseclf = LinearCSVMC()\n", 
            "metaclf = MappedClassifier(baseclf, SVDMapper())\n", 
            "cvte = CrossValidation(metaclf, NFoldPartitioner())\n", 
            "cv_results = cvte(ds)\n", 
            "print np.mean(cv_results)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "First we notice that little has been changed in the code and the results --\nthe error is slightly reduced, but still comparable. The critical line is\nthe second, where we create the ", 
            "[MappedClassifier](http://pymvpa.org/generated/mvpa2.clfs.meta.MappedClassifier.html#mvpa2-clfs-meta-mappedclassifier) from the\nSVM classifier instance, and a ", 
            "[SVDMapper](http://pymvpa.org/generated/mvpa2.mappers.svd.SVDMapper.html#mvpa2-mappers-svd-svdmapper) that\nimplements ", 
            "[singular value decomposition](http://en.wikipedia.org/wiki/Singular_value_decomposition) as a mapper."
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "- - -\n**Exercise**", 
            "\n\n", 
            "What might be the reasons for the error decrease in comparison to the\nresults on the dataset with voxel intensities?"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# you can use this cell for this exercise"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "- - -\n", 
            "\n\n", 
            "We know that mappers can be combined into complex processing pipelines, and\nsince ", 
            "[MappedClassifier](http://pymvpa.org/generated/mvpa2.clfs.meta.MappedClassifier.html#mvpa2-clfs-meta-mappedclassifier) takes any mapper as argument, we\ncan implement arbitrary preprocessing steps within the cross-validation\nprocedure. Let's say we have heard rumors that only the first two dimensions\nof the space spanned by the SVD vectors cover the \"interesting\" variance\nand the rest is noise. We can easily check that with an appropriate mapper:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "mapper = ChainMapper([SVDMapper(), StaticFeatureSelection(slice(None, 2))])\n", 
            "metaclf = MappedClassifier(baseclf, mapper)\n", 
            "cvte = CrossValidation(metaclf, NFoldPartitioner())\n", 
            "cv_results = cvte(ds)\n", 
            "svm_err = np.mean(cv_results)\n", 
            "print round(svm_err, 2)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Well, obviously the discarded components cannot only be noise, since the error\nis substantially increased. But maybe it is the classifier that cannot deal with\nthe data. Since nothing in this code is specific to the actual classification\nalgorithm we can easily go back to the kNN classifier that has served us well\nin the past."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "baseclf = kNN(k=1, dfx=one_minus_correlation, voting='majority')\n", 
            "mapper = ChainMapper([SVDMapper(), StaticFeatureSelection(slice(None, 2))])\n", 
            "metaclf = MappedClassifier(baseclf, mapper)\n", 
            "cvte = CrossValidation(metaclf, NFoldPartitioner())\n", 
            "cv_results = cvte(ds)\n", 
            "np.mean(cv_results) < svm_err"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Oh, that was even worse. We would have to take a closer look at the data to\nfigure out what is happening here."
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "- - -\n**Exercise**", 
            "\n\n", 
            "Inspect the confusion matrix of this analysis for both classifiers. What\ninformation is represented in the first two SVD components and what is not?\nPlot the samples of the full dataset after they have been mapped onto the\nfirst two SVD components. Why does the kNN classifier perform so bad in\ncomparison to the SVM (hint: think about the distance function)?"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# you can use this cell for this exercise"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "- - -\n", 
            "\n\n", 
            "In this tutorial part we took a look at classifiers. We have seen that,\nregardless of the actual algorithm, all classifiers are implementing the same\ninterface. Because of this, they can be replaced by another classifier without\nhaving to change any other part of the analysis code. Moreover, we have seen\nthat it is possible to enable and access optional information that is offered\nby particular parts of the processing pipeline."
          ]
        }
      ], 
      "metadata": {}
    }
  ]
}