{
  "metadata": {
    "name": "Spatio-temporal Analysis of event-related fMRI data"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Spatio-temporal Analysis of event-related fMRI data"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "In this example we are going to take a look at an event-related analysis of\ntimeseries data. We will do this on fMRI data, implementing a spatio-temporal\nanalysis of multi-volume samples. It starts as usual by loading PyMVPA and\nthe fMRI dataset."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from mvpa2.suite import *\n\nds = load_tutorial_data(roi=(36,38,39,40))"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The dataset we have just loaded is the full timeseries of voxels in the\nventral temporal cortex for 12 concatenated experiment runs. Although\noriginally a block-design experiment, we'll analyze it in an event-related\nfashion, where each stimulation block will be considered as an individual\nevent.\n\n", 
            "For an event-related analysis most of the processing is done on data\nsamples that are somehow derived from a set of events. The rest of the data\ncould be considered irrelevant. However, some preprocessing is only\nmeaningful when performed on the full timeseries and not on the segmented\nevent samples. An example is the detrending that typically needs to be done\non the original, continuous timeseries.\n\n", 
            "In its current shape our dataset consists of 1452 samples that represent\ncontiguous fMRI volumes. At this stage we can easily perform linear\ndetrending. We are going to do it per each experiment run (the dataset has\nto runs encoded in the `chunk` sample attribute), since we do not assume a\ncontiguous linear trend throughout the whole recording session."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# detrend on full timeseries\npoly_detrend(ds, polyord=1, chunks_attr='chunks')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Let's make a copy of the detrended dataset that we can later on use for\nsome visualization."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "orig_ds = ds.copy()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "We still need to normalize each feature (i.e. a voxel at this point). In\nthis case we are going to Z-score them, using the mean and standard\ndeviation from the experiment's rest condition. The resulting values might\nbe interpreted as \"activation scores\". We are again doing it per each run."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "zscore(ds, chunks_attr='chunks', param_est=('targets', 'rest'))"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "After detrending and normalization, we can now segment the timeseries into\na set of events. To achieve this we have to compile a list of event\ndefinitions first. In this example we will simply convert the block-design\nsetup defined by the samples attributes into events, so that each\nstimulation block becomes an event with an associated onset and duration.\nThe events are defined by a change in any of the provided attributes, hence\nwe get an event for starting stimulation block and any start of a run in\nthe experiment."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "events = find_events(targets=ds.sa.targets, chunks=ds.sa.chunks)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "`events` is a simple list of event definitions (each one being a\ndictionary) that can easily inspected for startpoints and duration of\nevents. Later on we want to look at the sensitivity profile ranging from\njust before until a little after each block. Therefore we are slightly\nmoving the event onsets prior the block start and request to extract a\nset of 13 consecutive volumes a as sample for each event.  Finally, in this\nexample we are only interested in ", 
            "`face` or ", 
            "`house` blocks."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# filter out events\nevents = [ev for ev in events if ev['targets'] in ['house', 'face']]\n\n# modify event start and set uniform duration\nfor ev in events:\n    ev['onset'] -= 2\n    ev['duration'] = 13"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Now we get to the core of an event-related analysis. We turn our existing\ntimeseries datasets into one with samples of timeseries segments.\n\n", 
            "PyMVPA offers ", 
            "[eventrelated_dataset()](http://pymvpa.org/generated/mvpa2.datasets.eventrelated.eventrelated_dataset.html#mvpa2-datasets-eventrelated-eventrelated-dataset)\nto perform this conversion -- given a list of events and a dataset with\nsamples that are sorted by time. If a dataset has information about\nacquisition time ", 
            "[eventrelated_dataset()](http://pymvpa.org/generated/mvpa2.datasets.eventrelated.eventrelated_dataset.html#mvpa2-datasets-eventrelated-eventrelated-dataset)\ncan also convert event-definition in real time."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "evds = eventrelated_dataset(ds, events=events)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Now we have our final dataset with spatio-temporal fMRI samples. Look at\nthe attributes of the dataset to see what information is available about\neach event. The rest is pretty much standard.\n\n", 
            "We want to perform a cross-validation analysis of a SVM classifier. We are\nnot primarily interested in its performance, but in the weights it assigns\nto the features. Remember, each feature is now voxel-timepoint, so we get a\nchance of looking at the spatio-temporal profile of classification relevant\ninformation in the data. We will nevertheless enable computing a confusion\nmatrix, so we can assure ourselves that the classifier is performing\nreasonably well, since only a generalizing classifier model is worth\ninspecting, as otherwise the assigned weights are meaningless."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "clf = LinearCSVMC()\nsclf = SplitClassifier(clf, enable_ca=['stats'])\n\n# Compute sensitivity, which internally trains the classifier\nanalyzer = sclf.get_sensitivity_analyzer()\nsensitivities = analyzer(evds)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Now let's look at the confusion matrix -- it turns out that the classifier\nperforms excellent."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print sclf.ca.stats"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "We could now convert the computed sensitivities back into a 4D fMRI image\nto look at the spatio-temporal sensitivity profile using the datasets\nmapper. However, in this example we are going to plot it for two example\nvoxels and compare it to the actual signal timecourse prior and after\nnormalization."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# example voxel coordinates\nexample_voxels = [(28,25,25), (28,23,25)]"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "First we plot the orginal signal after initial detrending. To do this, we\napply the timeseries segmentation to the original detrended dataset and\nplot to mean signal for all face and house events for both of our example\nvoxels."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "vx_lty = ['-', '--']\nt_col = ['b', 'r']\n\npl.subplot(311)\nfor i, v in enumerate(example_voxels):\n    slicer = np.array([tuple(idx) == v for idx in ds.fa.voxel_indices])\n    evds_detrend = eventrelated_dataset(orig_ds[:, slicer], events=events)\n    for j, t in enumerate(evds.uniquetargets):\n        pl.plot(np.mean(evds_detrend[evds_detrend.sa.targets == t], axis=0),\n               t_col[j] + vx_lty[i],\n               label='Voxel %i: %s' % (i, t))\npl.ylabel('Detrended signal')\npl.axhline(linestyle='--', color='0.6')\npl.legend()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "In the next step we do exactly the same again, but this time for the\nnormalized data."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "pl.subplot(312)\nfor i, v in enumerate(example_voxels):\n    slicer = np.array([tuple(idx) == v for idx in ds.fa.voxel_indices])\n    evds_norm = eventrelated_dataset(ds[:, slicer], events=events)\n    for j, t in enumerate(evds.uniquetargets):\n        pl.plot(np.mean(evds_norm[evds_norm.sa.targets == t], axis=0),\n               t_col[j] + vx_lty[i])\npl.ylabel('Normalized signal')\npl.axhline(linestyle='--', color='0.6')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Finally, we plot the associated SVM weight profile for each peristimulus\ntimepoint of both voxels. For easier selection we do a little trick and\nreverse-map the sensitivity profile through the last mapper in the\ndataset's chain mapper (look at `evds.a.mapper` for the whole chain).\nThis will reshape the sensitivities into `cross-validation fold x volume x\nvoxel features`."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "pl.subplot(313)\nsmaps = evds.a.mapper[-1].reverse(sensitivities)\n\nfor i, v in enumerate(example_voxels):\n    slicer = np.array([tuple(idx) == v for idx in ds.fa.voxel_indices])\n    smap = smaps.samples[:,:,slicer].squeeze()\n    plot_err_line(smap, fmt='ko', linestyle=vx_lty[i])\npl.xlim((0,12))\npl.ylabel('Sensitivity')\npl.axhline(linestyle='--', color='0.6')\npl.xlabel('Peristimulus volumes')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n\\[Visit [http://pymvpa.org/examples/eventrelated.html](http://pymvpa.org/examples/eventrelated.html) to view this figure\\]\n\n", 
            "This demo showed an event-related data analysis. Although we have performed\nit on fMRI data, an analogous analysis can be done for any timeseries-based\ndata in an almost identical fashion."
          ]
        }
      ], 
      "metadata": {}
    }
  ]
}