{
  "metadata": {
    "name": "The effect of different hyperparameters in GPR"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "The effect of different hyperparameters in GPR"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The following example runs Gaussian Process Regression (GPR) on a\nsimple 1D dataset using squared exponential (i.e., Gaussian or RBF)\nkernel and different hyperparameters. The resulting classifier\nsolutions are finally visualized in a single figure.\n\n", 
            "As usual we start by importing all of PyMVPA:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# Lets use LaTeX for proper rendering of greek\nfrom matplotlib import rc\nrc('text', usetex=True)\n\nfrom mvpa2.suite import *"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The next lines build two datasets using one of PyMVPA's data\ngenerators."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# Generate dataset for training:\ntrain_size = 40\nF = 1\ndataset = data_generators.sin_modulated(train_size, F)\n\n# Generate dataset for testing:\ntest_size = 100\ndataset_test = data_generators.sin_modulated(test_size, F, flat=True)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The last configuration step is the definition of four sets of\nhyperparameters to be used for GPR."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "# Hyperparameters. Each row is [sigma_f, length_scale, sigma_noise]\nhyperparameters = np.array([[1.0, 0.2, 0.4],\n                           [1.0, 0.1, 0.1],\n                           [1.0, 1.0, 0.1],\n                           [1.0, 0.1, 1.0]])"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The plotting of the final figure and the actually GPR runs are\nperformed in a single loop."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "rows = 2\ncolumns = 2\npl.figure(figsize=(12, 12))\nfor i in range(rows*columns):\n    pl.subplot(rows, columns, i+1)\n    regression = True\n    logml = True\n\n    data_train = dataset.samples\n    label_train = dataset.sa.targets\n    data_test = dataset_test.samples\n    label_test = dataset_test.sa.targets"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The next lines configure a squared exponential kernel with the set of\nhyperparameters for the current subplot and assign the kernel to the GPR\ninstance."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    sigma_f, length_scale, sigma_noise = hyperparameters[i, :]\n     kse = SquaredExponentialKernel(length_scale=length_scale,\n                                    sigma_f=sigma_f)\n     g = GPR(kse, sigma_noise=sigma_noise)\n     if not regression:\n         g = RegressionAsClassifier(g)\n     print g\n\n     if regression:\n         g.ca.enable(\"predicted_variances\")\n\n     if logml:\n         g.ca.enable(\"log_marginal_likelihood\")"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "After training GPR the predictions are queried by passing the test\ndataset samples and accuracy measures are computed."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    g.train(dataset)\n     prediction = g.predict(data_test)\n\n     # print label_test\n     # print prediction\n     accuracy = None\n     if regression:\n         accuracy = np.sqrt(((prediction-label_test)**2).sum()/prediction.size)\n         print \"RMSE:\", accuracy\n     else:\n         accuracy = (prediction.astype('l')==label_test.astype('l')).sum() \\\n                    / float(prediction.size)\n         print \"accuracy:\", accuracy"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "The remaining code simply plots both training and test datasets, as\nwell as the GPR solutions."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "\u00bb    if F == 1:\n         pl.title(r\"$\\sigma_f=%0.2f$, $length_s=%0.2f$, $\\sigma_n=%0.2f$\" \\\n                 % (sigma_f,length_scale,sigma_noise))\n         pl.plot(data_train, label_train, \"ro\", label=\"train\")\n         pl.plot(data_test, prediction, \"b-\", label=\"prediction\")\n         pl.plot(data_test, label_test, \"g+\", label=\"test\")\n         if regression:\n             pl.plot(data_test, prediction - np.sqrt(g.ca.predicted_variances),\n                        \"b--\", label=None)\n             pl.plot(data_test, prediction+np.sqrt(g.ca.predicted_variances),\n                        \"b--\", label=None)\n             pl.text(0.5, -0.8, \"$RMSE=%.3f$\" %(accuracy))\n             pl.text(0.5, -0.95, \"$LML=%.3f$\" %(g.ca.log_marginal_likelihood))\n         else:\n             pl.text(0.5, -0.8, \"$accuracy=%s\" % accuracy)\n\n         pl.legend(loc='lower right')\n\n     print \"LML:\", g.ca.log_marginal_likelihood"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }
      ], 
      "metadata": {}
    }
  ]
}