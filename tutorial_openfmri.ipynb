{
  "metadata": {
    "name": "Working with OpenFMRI.org data"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Working with OpenFMRI.org data"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Working with data from other researchers can be hard. There are lots of ways to\ncollect data, and even more ways to store it on a hard drive. This variability\nturns discovering the structure of a \"foreign\" dataset into a research project\nof its own.\n\n", 
            "Standardization is one way to make this easier and the ", 
            "[OpenFMRI](http://www.openfmri.org) project has\nproposed a scheme for structuring (task) fMRI dataset in order to facilitate\nautomated analysis. While there are other approaches to standardization, the\n", 
            "[layout proposed by OpenFMRI](https://openfmri.org/content/data-organization) is appealing, because it offers a good balance\nbetween the level of standardization and the required effort to achieve it.\n\n", 
            "PyMVPA offers convenient tools to work with dataset that are (somewhat)\ncompliant with the OpenFMRI structure. So independent of whether you plan on\nsharing your data or not, it may make sense to adopt these conventions, when\nworking with PyMVPA. Take a look at this tutorial and make up your mind whether\nthere is something about this convenience that you like. As a bonus, if you\nhave your dataset formated for OpenFMRI already, it becomes technically trivial\nto share it on openfmri.org later on -- for free. Here is how it looks like to\nwork with an OpenFMRI dataset, starting with the bare necessities:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from os.path import join as opj\n", 
            "import mvpa2\n", 
            "from mvpa2.datasets.sources import OpenFMRIDataset"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Assuming you downloaded and extracted a dataset from OpenFMRI.org into the\ncurrent directory, you will have a sub-directory (for example `ds105` if you\npicked the ", 
            "[Haxby et al, (2001) data](https://openfmri.org/dataset/ds000105)) that contains all files of the data\nrelease. In order to have PyMVPA access this data, we simply have to create a\nhandler that is pointed to this sub-directory. In order to spare you the 2GB\ndownload just to run this tutorial, we are using a minified version of that\ndataset in this demo which already comes with PyMVPA."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "path = opj(mvpa2.pymvpa_dataroot , 'haxby2001')\n", 
            "of = OpenFMRIDataset(path)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Through this handler we can access lots of information about this dataset.\nLet's start with what this dataset is all about."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print of.get_task_descriptions()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "We can immediately see that the dataset is concerned with a single task ", 
            "*object\nviewing* The descriptions are always returned as a dictionary that maps the\ntask ID (an integer number) to a verbal description. This is done, because a\ndataset can contain data for more than one task.\n\n", 
            "Other descriptive information, such as the number and IDs of the subjects in the\ndataset, as well as other supporting information specified in the\n`scan_key.txt` meta data file are also available:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print of.get_subj_ids()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "of.get_scan_properties()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "As you can see, subject IDs don't have to be numerical.\n\n", 
            "So far, the information we retrieved was rather simple and the advantages of\nbeing able to access them through an API will not become obvious until one\nstarts working with a lot of datasets simultaneously. So let's take a look at\nsome functionality that is more useful in the context of a single dataset.\n\n", 
            "For task fMRI, we are almost always interested in information about the\nstimulation model, i.e. when was any particular subject exposed to which\nexperiment conditions. All this information is readily available. Here is how\nyou get the number and IDs of all contained model specifications:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "of.get_model_ids()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "of.get_model_descriptions()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "This particular dataset contains a single model specification. With its\nnumerical ID we can query more information about the model:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "conditions = of.get_model_conditions(1)\n", 
            "print conditions"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print [c['name'] for c in conditions]"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "We can easily get a list of the condition names and their association with a\nparticular task. And with the task ID we can query the dataset for the number\n(and IDs) of all related BOLD run fMRI images."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print of.get_task_bold_run_ids(1)"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "If there would be actual data available for the `phantom` subject, we would\nsee it in the output too.\n\n", 
            "With this information we can access almost any item in this dataset that is\nrelated to task fMRI. Take a look at\n", 
            "[OpenFMRIDataset.get_bold_run_image()](http://pymvpa.org/generated/mvpa2.datasets.sources.openfmri.OpenFMRIDataset.html#mvpa2.datasets.sources.openfmri.OpenFMRIDataset.get_bold_run_image),\n", 
            "[OpenFMRIDataset.get_bold_run_dataset()](http://pymvpa.org/generated/mvpa2.datasets.sources.openfmri.OpenFMRIDataset.html#mvpa2.datasets.sources.openfmri.OpenFMRIDataset.get_bold_run_dataset),\nand the other methods in order to explore the possibilities.  After looking at\nall the raw information available in a dataset, let's take a look at some\nhigh-level functionality that is more interesting when actually working with a\ntask fMRI dataset.\n\n", 
            "For any supervised analysis strategy, for example a classification analysis, it\nis necessary to assign labels to data points. In PyMVPA, this is done by\ncreating a dataset with (at least) one sample attribute containing the labels\n-- one for each sample in the dataset. The\n", 
            "[OpenFMRIDataset.get_model_bold_dataset()](http://pymvpa.org/generated/mvpa2.datasets.sources.openfmri.OpenFMRIDataset.html#mvpa2.datasets.sources.openfmri.OpenFMRIDataset.get_model_bold_dataset)\nmethod is a convenient way of generating such a dataset directly from the\nOpenFMRI specification. As you'll see in a second, this methods uses any\nrelevant information contained in the OpenFMRI specification and we only need\nto fill in the details of how exactly we want the PyMVPA dataset to be created.\nSo here is a complete example:"
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from mvpa2.datasets.eventrelated import fit_event_hrf_model\n", 
            "ds = of.get_model_bold_dataset(\n         model_id=1,\n         subj_id=1,\n         flavor='25mm',\n         mask=opj(path, 'sub001', 'masks', '25mm', 'brain.nii.gz'),\n         modelfx=fit_event_hrf_model,\n         time_attr='time_coords',\n         condition_attr='condition')"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "So let's take this bit of code apart in order to understand what it is doing.\nWhen calling `get_model_bold_dataset()`, we specify the model ID and subject\nID, as well as the \"flavor\" of data we are interested in. Think of the flavor\nas different variants of the same raw fMRI time series (e.g. different set of\napplied preprocessing steps). We are using the \"25mm\" flavor, which is our\nminified variant of the original dataset, down-sampled to voxels with 25 mm edge\nlength.  Based on this information, the relevant stimulus model specifications\nare discovered and data files for the associated subject are loaded. This\nmethod could be called in a loop to, subsequently, load data for all available\nsubjects. In addition, we specify a mask image file to exclude non-brain voxels.\nOften these masks do not come with a data release and have to be created first.\n\n", 
            "Now for the important bits: The `modelfx` argument takes a, so-called,\nfactory method that can transform a time series dataset (each sample in the\ndataset is a time point at that stage) into the desired type of sample (or\nobservation). In this example, we have used\n", 
            "[fit_event_hrf_model()](http://pymvpa.org/generated/mvpa2.datasets.eventrelated.fit_event_hrf_model.html#mvpa2-datasets-eventrelated-fit-event-hrf-model) that is designed to\nperform modeling of each stimulation event contained in the OpenFMRI\nspecification. PyMVPA ships with three principal transformation methods that\ncan be used here: ", 
            "[fit_event_hrf_model()](http://pymvpa.org/generated/mvpa2.datasets.eventrelated.fit_event_hrf_model.html#mvpa2-datasets-eventrelated-fit-event-hrf-model),\n", 
            "[extract_boxcar_event_samples()](http://pymvpa.org/generated/mvpa2.datasets.eventrelated.extract_boxcar_event_samples.html#mvpa2-datasets-eventrelated-extract-boxcar-event-samples) and\n", 
            "[assign_conditionlabels()](http://pymvpa.org/generated/mvpa2.datasets.eventrelated.assign_conditionlabels.html#mvpa2-datasets-eventrelated-assign-conditionlabels). The difference\nbetween the three is that the latter simply assignes conditions labels to the\ntime point samples of a time series dataset, whereas the former two can do more\ncomplex transformations, such as temporal compression, or model fitting.  Note,\nthat is is possible to implement custom transformation functions for\n`modelfx`, but all common use cases should be supported by the three functions\nthat already come with PyMVPA.\n\n", 
            "All subsequent argument are passed on to the `modelfx`. In this example, we\nrequested all events of the same condition to be modeled by a regressor that is\nbased on a canonical hemodynamic response function (this requires the\nspecification of a dataset attribute that encodes the timing of a time series\nsamples; `time_attr`)."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print ds"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "This all led to an output dataset with 96 samples, one sample per each of the\neight condition in each of the 12 runs."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print ds.sa.condition"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "print ds.sa.chunks"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "Each value in the sample matrix corresponds to the estimated model parameter\n(or weight) for the associated voxel. Model fitting is performed individually\nper each run. The model regressors, as well as numerous other bits of\ninformation are available in the returned dataset.\n\n", 
            "Depending on the type of preprocessing that was applied to this data flavor,\nthe dataset `ds` may be ready for immediate analysis, for example in\na cross-validated classification analysis. If further preprocessing steps\nare desired, the `preproc_ds` argument of\n", 
            "[OpenFMRIDataset.get_model_bold_dataset()](http://pymvpa.org/generated/mvpa2.datasets.sources.openfmri.OpenFMRIDataset.html#mvpa2.datasets.sources.openfmri.OpenFMRIDataset.get_model_bold_dataset)\nprovides an interface for applying additional transformations, such as temporal\nfiltering, to the time series data of each individual BOLD fMRI run."
          ]
        }
      ], 
      "metadata": {}
    }
  ]
}