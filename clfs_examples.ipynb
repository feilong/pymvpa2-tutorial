{
  "metadata": {
    "name": "Classifier Sweep"
  }, 
  "nbformat": 3, 
  "nbformat_minor": 0, 
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading", 
          "level": 1, 
          "metadata": {}, 
          "source": [
            "Classifier Sweep"
          ]
        }, 
        {
          "cell_type": "markdown", 
          "metadata": {}, 
          "source": [
            "\n\n", 
            "This examples shows a test of various classifiers on different datasets."
          ]
        }, 
        {
          "cell_type": "code", 
          "collapsed": false, 
          "input": [
            "from mvpa2.suite import *\n\n# no MVPA warnings during this example\nwarning.handlers = []\n\ndef main():\n\n    # fix seed or set to None for new each time\n    np.random.seed(44)\n\n\n    # Load Haxby dataset example\n    haxby8 = load_example_fmri_dataset(literal=True)\n    haxby8.samples = haxby8.samples.astype(np.float32)\n\n    # preprocess slightly\n    poly_detrend(haxby8, chunks_attr='chunks', polyord=1)\n    zscore(haxby8, chunks_attr='chunks', param_est=('targets', 'rest'))\n\n    haxby8_no0 = haxby8[haxby8.targets != 'rest']\n\n    dummy2 = normal_feature_dataset(perlabel=30, nlabels=2,\n                                  nfeatures=100,\n                                  nchunks=6, nonbogus_features=[11, 10],\n                                  snr=3.0)\n\n    for (dataset, datasetdescr), clfs_ in \\\n        [\n        ((dummy2,\n          \"Dummy 2-class univariate with 2 useful features out of 100\"),\n          clfswh[:]),\n        ((pure_multivariate_signal(8, 3),\n          \"Dummy XOR-pattern\"),\n          clfswh['non-linear']),\n        ((haxby8_no0,\n          \"Haxby 8-cat subject 1\"),\n          clfswh['multiclass']),\n        ]:\n        # XXX put back whenever there is summary() again\n        #print \"%s\\n %s\" % (datasetdescr, dataset.summary(idhash=False))\n        print \" Classifier on %s\\n\" \\\n                \"                                          :   %%corr   \" \\\n                \"#features\\t train  predict full\" % datasetdescr\n        for clf in clfs_:\n            print \"  %-40s: \"  % clf.descr,\n            # Let's prevent failures of the entire script if some particular\n            # classifier is not appropriate for the data\n            try:\n                # Change to False if you want to use CrossValidation\n                # helper, instead of going through splits manually to\n                # track training/prediction time of the classifiers\n                do_explicit_splitting = True\n                if not do_explicit_splitting:\n                    cv = CrossValidation(\n                        clf, NFoldPartitioner(), enable_ca=['stats', 'calling_time'])\n                    error = cv(dataset)\n                    # print cv.ca.stats\n                    print \"%5.1f%%      -    \\t   -       -    %.2fs\" \\\n                          % (cv.ca.stats.percent_correct, cv.ca.calling_time)\n                    continue\n\n                # To report transfer error (and possibly some other metrics)\n                confusion = ConfusionMatrix()\n                times = []\n                nf = []\n                t0 = time.time()\n                #TODO clf.ca.enable('nfeatures')\n                partitioner = NFoldPartitioner()\n                for nfold, ds in enumerate(partitioner.generate(dataset)):\n                    (training_ds, validation_ds) = tuple(\n                        Splitter(attr=partitioner.space).generate(ds))\n                    clf.train(training_ds)\n                    #TODO nf.append(clf.ca.nfeatures)\n                    predictions = clf.predict(validation_ds.samples)\n                    confusion.add(validation_ds.targets, predictions)\n                    times.append([clf.ca.training_time, clf.ca.predicting_time])\n\n                tfull = time.time() - t0\n                times = np.mean(times, axis=0)\n                #TODO nf = np.mean(nf)\n                # print confusion\n                #TODO print \"%5.1f%%   %-4d\\t %.2fs  %.2fs   %.2fs\" % \\\n                print \"%5.1f%%       -   \\t %.2fs  %.2fs   %.2fs\" % \\\n                      (confusion.percent_correct, times[0], times[1], tfull)\n                #TODO      (confusion.percent_correct, nf, times[0], times[1], tfull)\n            except LearnerError, e:\n                print \" skipped due to '%s'\" % e\n\nif __name__ == \"__main__\":\n    main()"
          ], 
          "language": "python", 
          "metadata": {}, 
          "outputs": []
        }
      ], 
      "metadata": {}
    }
  ]
}